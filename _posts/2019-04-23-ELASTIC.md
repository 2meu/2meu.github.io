---
title: ELASTIC
date: 2019-04-23
---

## 개요

Logstash : collect data, filter data

- Collect data: 다양한 [입력지원](https://www.elastic.co/guide/en/logstash/current/input-plugins.html)을 통해 여러가지 공통 소스에서 이벤트를 동시에 가져옵니다.
  - elasticsearch
  - file
  - github
  - http
  - etc...

- Filter data: grok(data parsing - re module과 비슷): 데이터가 소스에서 저장소로 이동하는 과정에서 구문 분석 + 필드 식별을 통해 구조화 해줍니다.
  - aggregate
  - alter
  - csv
  - date
  - grok: parse arbitrary text and structure it.(필드 분석, 정규화 분석)
    - ```
    Examples: With that idea of a syntax and semantic, we can pull out useful fields from a sample log like this fictional http request log:

    55.3.244.1 GET /index.html 15824 0.043
    The pattern for this could be:

    %{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration}
    A more realistic example, let’s read these logs from a file:

    input {
      file {
        path => "/var/log/http.log"
      }
    }
    filter {
      grok {
        match => { "message" => "%{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration}" }
      }
    }
    After the grok filter, the event will have a few extra fields in it:

    client: 55.3.244.1
    method: GET
    request: /index.html
    bytes: 15824
    duration: 0.043
    ```

- 출력: 원하는 곳으로 데이터를 라우팅할 수 있습니다. 다양한 출력을 지원하기 때문에 여러 저장소로 데이터를 다운스트림할 수 있습니다.


Elastic search(store data) :

- 데이터를 쉽게 처리하고 엑세스 할 수 있도록 합니다.
- document 기반 검색 엔진
```
$
{
  "name" : "Craft"
  "geo" : {
    "city" : "Budapest",
    "lat" : 47.49, "lon" : 19.04
  }
}
```

  - CRUD REST API를 통한 데이터 추가, 업데이트, 검색 및 삭제
  - 토크나이징, 토큰 필터링을 통한 텍스트 분석(Analysis)
  - 기본적인 검색 쿼리
  - 애그리게이션(집계) - Elasticsearch 의 데이터 집계와 분석을 위한 기능

Kibana : data visualizations


## 설치 + 실행

https://m.blog.naver.com/PostView.nhn?blogId=ambition0917&logNo=221120007065&proxyReferer=https%3A%2F%2Fwww.google.com%2F

Elasticsearch 다운로드 페이지: https://www.elastic.co/downloads/elasticsearch
실행: bin/elasticsearch.bat
접속확인 url: localhost:9200

Kibana 다운로드 페이지: https://www.elastic.co/downloads/kibana
실행: bin/kibana.bat
접속확인 url: localhost:5601

로컬 환경에서 간단히 데이터 조회 및 Kibana를 통한 데이터 시각화에 사용할 것이라 기본설정을 유지한다.

Elasticsearch를 실 서비스등에 사용하고자 한다면 노드나 인덱스 관련 좀 더 많은 설정을 필요로한다.

## Kibana 설정 변경

![image](https://user-images.githubusercontent.com/48308562/56559102-92675700-65db-11e9-9b2f-d3c8d673921a.png)


## 수행

**RDB -> Elastic search structure**
Database -> Index
Table -> Type
Row -> Document
Column -> Field
Schema -> Mapping

**RDB -> Elastic search Query**
Select -> Get
Update -> Put
Insert -> Post
delete -> delete

##

---
title: papers
date: 2019-04-15
categories : [Papers]
---

## tfidf : [Using TF-IDF to Determin Word Relevance in Document Queries](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.121.1424&rep=rep1&type=pdf)

- high TF-IDF numbers imply a strong relationship with the document they appear in
- tf-idf가 높은 단어가 있는 문서는 읽는이에게 관심이 높은 문서일 가능성이 있다.
- naive can result that it approach only to make high sum of f(w,d) - 한 문서에 존재하는 단어 수
- tf-idf: considering both f(w,d) and f(w,D) results high quality.
- Clearly, IF-IDF is much more powerful that its naive counterpart
- Have limitation : ex) synonyms and (dru <-> drugs) - For large document collections, this could present an escalating problem
actiav

## [Voice Recognition using Neural Networks](https://drive.google.com/drive/search?q=viewcontent)

- process : Mic -> ADC -> Parameter extraction -> Pattern matching(template memory) -> output device
- voice recognition system : Mic -> PC sound card -> Digital Signal Processing -> Neural Network -> output
- technique to extract unique features for voice Recognition is "PSD"
- Power Spectral Density(PSD) is computed by taking the magnitude-squared result of the Fourier transform
- *The PSD of a voice sample contains unique features attributed to an individual and these are used in our studies*
- PSD values are presented in a vector form to the pattern matching
- the experiment will only use PSD technique
- <Pattern Matching Using Neural Networks>
- Training Sample Input are PSD from voice of same phrase from many other people and output is the specific person who make this voice.
- ANN(Artificial Neural Networks) is used  for pattern matching
- 7 voice samples from four different people speaks same phrase
- 100% success rate with trained sample but 66% success rate with untrained sample
- *<Self Organizing Maps(SOMs) has a better recognition ability compared to the backpropagation neural network>*
- 7 voice samples from four different people same phrase
- 78% success rate with untrained sample
- conclusion : The use of artificial neural networks in voice recognition with PSD and SOM has proved that a fair amount of success.

- SOM(자기조직화지도)

차원축소와 군집화를 동시에 수행하는 기법

SOM이란 사람이 눈으로 볼 수 있는 저차원(2차원 또는 3차원) 격자에 고차원 데이터의 각 개체들이 대응하도록 인공신경망과 유사한 방식으로 순집을 도출해 내는 기법.


## [librosa: Audio and Music Signal Analysis in Python](http://conference.scipy.org/proceedings/scipy2015/pdfs/brian_mcfee.pdf)


## [Techniques for feature extraction in speech recognition system: a comparative study](https://2meu.github.io/2DUB/#)

- There are many ways to describe the speech signal.
- There are most used methods with there importance
- speech signal is represented by short term amplitude spectrum of wave form
- This allows us to extract features based on the short term amplitude spectrum from speech(phonemes).
- Theoretically, it should be possible to recognize speech directly from the digitized waveform. However, because of the large variability of the speech signal, it is better to perform some feature extraction that would reduce that variability.
- 예를들어 음성과 비음성이 함께 존재하는 오디오 파일에서는 주기적으로 발생하는 pitch 정보를 제거 함으로써
- 1. LPC(Linear Predictive Coding)
- specifit speech sample at the current time can be approximated as a linear combination of past speech samples
- LPC is based on human speech production(성문, 성악, 입술 radiation)
- give a unique set of predictor coefficients per 20ms normally.
- LPC 분석은 각 프레임마다(20ms) pitch-detecting algorithm을 사용해 voice인지 unvoice인지 판단하는 작업도 진행한다. 하지만 이 predictor coefficients는 variance가 커서 실제로 사용하지 않고 cepstral coefficent라는 파라미터로 robust set에서 사용된다.
- 2. MFCC(Mel Frequency Cepstral Coefficent) - 멜 주파수 결정(수정) 계수
- There are normally 20 MFCC coefficients
- You can learn the temporal changes in the speech segment to mark landmarks. *HMM* is a very good machine learning tool to learn temporal relationship in data. - old ver
- You can learn the distribution of the vectors in speech segments and use it for classification of test speech. For this you can use *GMM* modeling.
- You can use *SVM* for the classification purpose.
